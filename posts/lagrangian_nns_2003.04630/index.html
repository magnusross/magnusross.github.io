<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>  </title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Lagrangian Neural Networks BibTeX @article{cranmer2020lagrangian, title={Lagrangian neural networks}, author={Cranmer, Miles and Greydanus, Sam and Hoyer, Stephan and Battaglia, Peter and Spergel, David and Ho, Shirley}, journal={arXiv preprint arXiv:2003.04630}, year={2020} } Summary Use constraint of EL equations to force NN to conserve energy, leading to NN that can better predict dynamics for physical systems such as double pendulum.
Description  Lagrangian is paramterised by NN in this case MLP Use vector EL equstions, then apply time derive to get acceleration." />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<link rel="canonical" href="/posts/lagrangian_nns_2003.04630/" />




<link rel="stylesheet" href="/assets/style.css">

  <link rel="stylesheet" href="/assets/blue.css">






<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/img/apple-touch-icon-144-precomposed.png">

  <link rel="shortcut icon" href="/img/favicon/blue.png">



<meta name="twitter:card" content="summary" />

<meta name="twitter:creator" content="" />


<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content=" :: ">
<meta property="og:description" content="Lagrangian Neural Networks BibTeX @article{cranmer2020lagrangian, title={Lagrangian neural networks}, author={Cranmer, Miles and Greydanus, Sam and Hoyer, Stephan and Battaglia, Peter and Spergel, David and Ho, Shirley}, journal={arXiv preprint arXiv:2003.04630}, year={2020} } Summary Use constraint of EL equations to force NN to conserve energy, leading to NN that can better predict dynamics for physical systems such as double pendulum.
Description  Lagrangian is paramterised by NN in this case MLP Use vector EL equstions, then apply time derive to get acceleration." />
<meta property="og:url" content="/posts/lagrangian_nns_2003.04630/" />
<meta property="og:site_name" content="" />

  
    <meta property="og:image" content="/img/favicon/blue.png">
  

<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">













</head>
<body class="">


<div class="container center headings--one-size">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/about">
  <div class="logo">
    Magnus Ross
  </div>
</a>

    </div>
    <div class="menu-trigger">menu</div>
  </div>
  
    <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
        
          <li><a href="/about">About</a></li>
        
      
        
          <li><a href="/posts">Posts</a></li>
        
      
      
    

    
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="/about">About</a></li>
      
    
      
        <li><a href="/posts">Posts</a></li>
      
    
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
<div class="post">
  <h1 class="post-title">
    <a href="/posts/lagrangian_nns_2003.04630/"></a></h1>
  <div class="post-meta">
    
    
  </div>

  

  

  

  <div class="post-content"><div>
        <h1 id="lagrangian-neural-networks">Lagrangian Neural Networks<a href="#lagrangian-neural-networks" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h1>
<h4 id="bibtex">BibTeX<a href="#bibtex" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h4>
<pre><code class="language-{BibTeX}" data-lang="{BibTeX}">@article{cranmer2020lagrangian,
  title={Lagrangian neural networks},
  author={Cranmer, Miles and Greydanus, Sam and Hoyer, Stephan and Battaglia, Peter and Spergel, David and Ho, Shirley},
  journal={arXiv preprint arXiv:2003.04630},
  year={2020}
}
</code></pre><h4 id="summary">Summary<a href="#summary" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h4>
<p>Use constraint of EL equations to force NN to conserve energy, leading to NN that can better predict dynamics for physical systems such as double pendulum.</p>
<h4 id="description">Description<a href="#description" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h4>
<ul>
<li>Lagrangian is paramterised by NN in this case MLP</li>
<li>Use vector EL equstions, then apply time derive to get acceleration.
<ul>
<li>$\frac{d}{dt}  \nabla_{\dot q} \mathcal{L} = \nabla_{q} \mathcal{L}$</li>
<li>$(\nabla_{\dot q}\nabla_{\dot q}^{\top}\mathcal{L})\ddot q + (\nabla_{q}\nabla_{\dot q}^{\top}\mathcal{L}) \dot q = \nabla_q \mathcal{L}$</li>
<li>$\ddot q = (\nabla_{\dot q}\nabla_{\dot q}^{\top}\mathcal{L})^{-1}[\nabla_q \mathcal{L} - (\nabla_{q}\nabla_{\dot q}^{\top}\mathcal{L})\dot q]$</li>
</ul>
</li>
<li>Now $\ddot q$ is found can use it to step forward parameters $q$ and $\dot{q}$</li>
<li>Train by comparing $\dot{x}_{true} = (\dot{q}_{true}, \ddot q_{true})$ to $\dot{x}_{true}$ using MSE and backprop through above equation.</li>
<li>Apply to double pendulum, relativistic particle</li>
<li>Can also use on lagrangian fields by discretising field into $\phi_i$. For large number of field samples, this becomes hard since large matrix must be inverted in $\ddot q$ equations.</li>
<li>Can simplify by assuming lagrangain onyl allows dependence between nighbouriing $\phi_i$, then using sparse matrix inversion. Classic example being the continous limit of string of spings, where $V \sim (\phi_{i} - \phi_{i+1})^2$, leanding to wave equation.</li>
</ul>
<h4 id="implementation">Implementation<a href="#implementation" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h4>
<ul>
<li>Followign doubel pendulum example</li>
<li>JAX is used throughout</li>
<li>They use 2 different non NN methods:
<ul>
<li>Specify lagrangian, calculate deriavtives by hand to calulate explicit $\dot x$, use <code>odeint</code> to step forward, using <a href="https://diego.assencio.com/?index=1500c66ae7ab27bb0106467c68feebc6">this blog post</a>.</li>
<li>Sepcify lagranagian, use JAX to autodiff it and calculate<br>
3rd equation above, find $\dot x$, use this in <code>odeint</code>.</li>
</ul>
</li>
<li>To illustrate the validity of autodiff vs analyitic, they show the differnence in the solutions is approximatly equivilent to an $O(10^{-10})$ purtabtiaon to analytic.</li>
<li>For training data analytic method is used, seems like they only use one example, ie one initialisation of $q$ for train and test data. Run 2N timesteps analytically use 1st N for train 2nd for test.</li>
</ul>
<h4 id="thoughts">Thoughts<a href="#thoughts" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h4>
<ul>
<li>How could you add differnet contraints to NN? For example could you make the NN covarient? Lots of thoguhts about symmeteris in ML <a href="https://astroautomata.com/blog/nn-symmetries/">here</a>.</li>
<li>How practically useful is this? Seems like people use in robotics.</li>
<li>Don't get initialisations section.</li>
</ul>
<h4 id="related">Related<a href="#related" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h4>
<ul>
<li>Generalizing Convolutional Neural Networks for Equivariance to Lie Groups on Aribitrary Continuous Data by Finzi et al.</li>
<li>Learning Invariances using the Marginal Likelihood by van der Wilk et al.</li>
</ul>

      </div></div>

  
  
<div class="pagination">
    <div class="pagination__title">
        <span class="pagination__title-h">Read other posts</span>
        <hr />
    </div>
    <div class="pagination__buttons">
        
        <span class="button previous">
            <a href="/posts/garage_records/">
                <span class="button__icon">←</span>
                <span class="button__text">3 Nice Garage Records</span>
            </a>
        </span>
        
        
    </div>
</div>

  

  

</div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2020 Powered by <a href="http://gohugo.io">Hugo</a></span>
    
        <span>:: Theme made by <a href="https://twitter.com/panr">panr</a></span>
      </div>
  </div>
</footer>

<script src="/assets/main.js"></script>
<script src="/assets/prism.js"></script>

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    svg: {
      fontCache: 'global'
    }
  };
  </script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>





  
</div>

</body>
</html>
